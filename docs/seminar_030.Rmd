---
title: 'Семинар 3. Кластерный анализ'
date: 'May 31, 2018'
output:
  html_document:
    keep_md: no
    number_sections: yes
    toc: yes
lang: ru-RU
editor_options:
  chunk_output_type: console
---


Признаемся: часть сокровищ R мы утаили :)

Много пакетов R можно поставить с официального репозитория CRAN через `Tools` - `Install packages`.
Однако несметные богатства пакетов лежат на github!
Сайт [rdrr.io](https://rdrr.io) позволяет искать сокровища :)

О новых прикольных пакетах обычно рассказывают на [r-bloggers.com](https://www.r-bloggers.com).

Чтобы поставить пакет нужно знать имя разработчика и название пакета.
Мы поставим пакет `patchwork` от `thomasp85`.
Томас придумал простой язык, чтобы рисовать несколько графиков рядом.

Ставим пакет Томаса:
```{r, eval=FALSE}
devtools::install_github('thomasp85/patchwork')
```

Как правило, разработчики интригующе описывают пакет прямо на гитхабе.
Например, описание пакета [у Томаса](https://github.com/thomasp85/patchwork).


Установка выполняется один раз :)

Теперь подключаем пакеты!

```{r}
library(tidyverse) # обработка данных, графики...
library(skimr)# описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(cluster) # кластерный анализ
library(factoextra) # визуализации kmeans, pca,
library(broom) # стандартизация информации о модели
library(dendextend) # визуализация дендограмм
library(patchwork) # удобное расположение графиков рядом
```



# Соединение таблиц

Таблицы можно создавать и самим c помощью функции `tibble()`.

```{r}
mx <- tibble(ID = c('A', 'B', 'C', 'D', 'E'),
           x = c(1, 2, 4, 1, 8))
mx
```

* Упражнение 12.

Создайте таблицу `my`, с двумя столбцами: `ID` и `y`, и пятью значениями в каждом.
Столбец `y` можно заполнить числами произвольно.

```{r}
# my <- tibble(ID = c('A', 'C', 'D', 'F', 'E'),
#             y = c(___))
# my
```

Таблицы можно соединять! Существует четыре способа сделать это:
- `left_join(x, y, by = 'colname')` сохраняет все наблюдения в таблице `x`
- `right_join(x, y, by = 'colname')` сохраняет все наблюдения в таблице `y`
- `full_join(x, y, by = 'colname')` сохраняет наблюдения из обеих таблиц
- `inner_join(x, y, by = 'colname')` объединяет только те строки обеих таблиц, в которых нет пропущенных наблюдений

* Упражнение 13.

Экспериментируем!

```{r}
# left_join(mx, my, by = 'ID')
# right_join(mx, my, by = 'ID')
# inner_join(mx, my, by = 'ID')
# full_join(mx, my, by = 'ID')
```

- Сколько наблюдений получается в объединённой таблице в каждом случае?

* Упражнение 14.

Нужно объединить таблицы `flights` и `weather` о вылетах из Нью-Йорка сразу по нескольким столбцам!

- 'Бросьте взгляд' на обе таблицы. Какие столбцы совпадают?
```{r}
# glimpse(___)
# ___
```

- Присоедините к таблице `flights` таблицу `weather` с помощью функции  `left_join()`.
В качестве аргумента `by` используйте вектор из названий общих столбцов: `year`, `month`, `day`, `hour` и `origin`.
- Сколько наблюдений в объединённой таблице?

```{r}
# left <- left_join(___, ____, by = c('year', 'month', 'day', 'hour', 'origin'))
# glimpse(___)
```

- Повторите соединение двух таблиц, но используя `inner_join()`. Сколько наблюдений в получившейся таблице?
- В чём разница `left_join` и `inner_join`?

```{r}
# inner <- inner_join(___, ___, ___)
# ___
```

# Длинные и широкие таблицы


Таблицы бывают длинными и широкими!
При поступлении нового наблюдения длинная растёт в длину, а широкая может и в ширину :)

Возьмём квартальные данные [Росстата](http://www.gks.ru/free_doc/new_site/vvp/kv/tab35.htm)
о ВВП по источникам доходов.

```{r}
gdp <- import('gdp.xls')
glimpse(gdp)
gdp
```

Обнаружив неудачное название переменной переименуем её сразу!
```{r}
gdp <- rename(gdp, indicator = X__1)
```

Чтобы превратить широкую таблицу в длинную, нужна функция `melt()` из пакета `reshape2`.

Столбцы растают и стекут в новую переменную `year`.
Если столбец нужно сохранить, то его надо перечислить в списке `id`.

```{r}
long_gdp <- melt(gdp, id = 'indicator', variable.name = 'year')
head(long_gdp, 30) # первые 30 наблюдений
```

Чтобы сделать обратное — перевести длинную таблицу в широкую — понадобится функция `dcast()`.

Здесь тупому компьютеру умный Homo Sapiens укажет:
  - какая переменная пойдёт по строкам новой таблицы: `cut`
  - какая переменная пойдёт по столбцам новой таблицы: `color`
  - какая переменная пойдёт внутрь таблицы: `price`
  - как реагировать компьютеру, если окажется в данных несколько кандидатов в одну ячейку таблицы: взять `mean`

```{r}
dcast(diamonds, cut ~ color, value.var = "price", fun.aggregate = mean)
```

* Упражнение 15.

Из данных про воздух в Нью-Йорке `airquality` сделайте длинную таблицу.
В качестве идентификаторов возьмите переменные `Month` и `Day`.


```{r}
# air_long <- melt(___, id = c('Month', 'Day')) # id оставлеет указанные столбцы
# air_long
```

А из получившейся длинной таблицы восстановите исходную!

```{r}
# air_wide <- dcast(___, Day + Month ~ ___) # вместо пропуска должна быть переменная с несколькими значениями
# air_wide
```




% операции с NA и простейшие алгоритмы заполнения удалении
% нужен пакет с графиками для работы с NA (О)

# Кластеризация k-means

Для примера возьмём данные по потреблению протеинов Европе из книги [Practial Machine Learning Cookbook](https://github.com/PacktPublishing/Practical-Machine-Learning-Cookbook/blob/master/Chapter%2003/Data/Europenaprotein.csv).
Сначала, как всегда, загрузим их и посмотрим описательные статистики.

```{r}
df <- import('Europenaprotein.csv')
skim(df)
```

- Есть ли в данных пропущенные наблюдения?

Затем отмасштабируем данные с помощью встроенной функции `scale()`.
Поскольку она может работать только с числами, первый столбец `Country` ей передавать не нужно.
Результат сохраним в матрице `df.stand` и сделаем из неё `data.frame`.

- Посмотрите на описательные статистики. Что стало со средним значением и стандартным отклонением переменных?

```{r}
df_stand <- mutate_if(df, is.numeric, scale)

# rownames(df.stand) = df$Country
skim(df_stand)
```

* Упражнение 1.

- Посмотрите на описательные статистики встроенного набора данных об арестах в США.
- Отмасштабируйте данные и сохраните их в переменную `usa.stand`.
- Проверьте, что всё получилось :)

```{r}
usa <- USArrests
skim(___)

usa_stand <- ___
___
```

Выполним кластеризацию методом k-средних с помощью функции `kmeans`.
В качестве аргументов укажем отмасштабированные данные `x` и количество кластеров `centers`.
Пока мы не знаем, как выбирать оптимальное количество кластеров, поэтому предположим, что их три.
Сохраним результат этого действия в переменной `k.means.fit`.

```{r}
k_means_fit <- kmeans(x = df_stand, centers = 3)
k_means_fit
# здесь график! (О) посмотреть на данные
```

* Упражнение 2.

Кластеризуйте отмасштабированные данные по арестам в США.
В выборе числа кластеров доверьтесь интуиции.

```{r}
k_means_usa <- kmeans(___, centers = ___)
```

В списке `k_means_fit` лежит куча разной информации!
Выведем список доступных блоков информации, которые возвращает функция `kmeans`, командой `attributes()`.
Теперь, зная, что искать, мы можем посмотреть, например,
на координаты центра кластеров или количество объектов в каждом из них.

```{r}
attributes(k.means.fit)

k.means.fit$centers
k.means.fit$cluster
k.means.fit$size
```

Другой способ структурировать вывод `kmeans` — использовать команду `tidy` из пакета `broom`.

```{r}
tidy(k.means.fit)
```

Первые девять неназванных переменных — центры кластеров по каждой переменной.

<!--
TODO: ещё в самом RStudio можно посмотреть (Б)
-->

Осталось только визуализировать результаты!
Для этого будем использовать команду `fviz_cluster()` из пакета `factoextra`.
Её аргументы — результат кластеризации (в нашем случае — `k.means.fit`),
исходные данные и ещё куча настроек вроде размера точек и цвета наблюдений-выбросов.
Мы только попросим выделять цветом кластеры по их границам и укажем аргумент `ellipse.type = 'convex'`.

```{r}
fviz_cluster(object = k.means.fit, data = df.stand,
             ellipse.type = 'convex')
```

* Упражнение ???.

Визуализируйте результаты кластеризации.

```{r}
fviz_cluster(___, data = ___, ellipse.type = 'convex')
```

- Пересекаются ли кластеры?
- Разумно ли изменить количество кластеров?


Как понять, сколько кластеров брать оптимально?
Один из способов сделать это — воспользоваться командой `fviz_nbclust` из пакета `factoextra`.

заботать эти методы!

```{r}
fviz_nbclust(df.stand, kmeans, method = 'wss') +
  labs(subtitle = 'Elbow method')
fviz_nbclust(df.stand, kmeans, method = 'silhouette') +
  labs(subtitle = 'Silhouette method')
fviz_nbclust(df.stand, kmeans, method = 'gap_stat') +
  labs(subtitle = 'Gap statistic method')
```

<!-- (Б)
TODO: объединение диаграмм в одну https://github.com/thomasp85/patchwork
-->

* Упражнение ???.

<!-- (Б)
TODO: дописать код для упражнения:
-->

Проверьте, совпадает ли выбранное вами число кластеров с оптимальным.
Изобразите все три диаграммы вместе.



<!-- (Б)
TODO: добавить метки кластеров к исходным данным
-->


# Иерархическая кластеризация

Другой способ разбить данные на группы — иерархическая кластеризация.
Но, в отличие от метода k-средних, она работает с матрицей расстояний,
поэтому первым делом посчитаем её!
Для этого будем использовать функцию `dist()`.
Передадим ей стандартизированные данные и укажем явно, как считать расстояния с помощью аргумента `method`.
О всех остальных опциях можно узнать в справке.

```{r}
df.dist <- dist(x = df.stand, method = 'euclidian')
```

Расстояния тоже можно визуализировать!
Сделаем это командой `fviz_dist` из пакета `factoextra`.

```{r}
fviz_dist(df.dist)
```

* Упражнение ???.

Посчитайте матрицу расстояний для `usa.stand` и визуализируйте её.

```{r}
usa.dist <- dist(___, method = 'euclidian')
fviz_dist(___)
```

Затем полученную матрицу расстояний передадим функции `hclust()`, которая и кластеризует данные.

TODO: заменить на hcut (?): (Б)


```{r}
h.fit <- hclust(df.dist, method = 'ward.D2')
```

С помощью функции `fviz_dend` визуализируем результат кластеризации.
Укажем несколько аргументов, чтобы сделать дендограмму красивее,
а полный перечень найдётся в справке.

```{r}
fviz_dend(h.fit, k = 4, # количесвто групп
          cex = 0.5, # размер подписи
          color_labels_by_k = TRUE) # цвет подписей по группам
```

* Упражнение ???.

- Сделайте иерархичискую кластеризацию на данных об арестах.
Не забудьте, что функции `hclust()` мы передаём матрицу расстояний!

- Визуализируйте результат кластеризации.
Выделите на графике четыре группы и сделайте подписи цветными.

TODO: заменить на hcut?: (Б)
```{r}
usa.fit <- hclust(___, method = 'ward.D2')
fviz_dend(___, k = ___, # количесвто групп
          cex = 0.5, # размер подписи
          color_labels_by_k = ___) # цвет подписей по группам
```

<!-- (О)
TODO: визулизация корреляций: может быть есть в corrplot
корреляция с предварительной (иерархической) кластеризацией переменных
-->

<!-- (Б)
TODO: добавить метки кластеров к исходным данным
-->

% ссылка на разные картинки для иерархической кластеризации (Б)

Ура! :)
