---
title: 'Семинар 4. Факторный анализ'
date: 'Июнь, 7, 2018'
output:
  html_document:
    keep_md: no
    number_sections: yes
    toc: yes
lang: ru-RU
editor_options:
  chunk_output_type: console
---



```{r}
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных

library(cluster) # кластерный анализ
library(factoextra) # визуализации kmeans, pca
library(dendextend) # визуализация дендрограмм

library(corrplot) # визуализация корреляций

library(broom) # метла превращает результаты оценивания моделей в таблички

library(patchwork) # удобное расположение графиков рядом

library(nycflights13) # данные о полётах в Нью-Йорке
```



# Про внутригрупповые и межгрупповые дисперсии :)


Снова возьмём данные по потреблению протеинов Европе из книги [Practial Machine Learning Cookbook](https://github.com/PacktPublishing/Practical-Machine-Learning-Cookbook/blob/master/Chapter%2003/Data/Europenaprotein.csv).
Загрузим их и посмотрим описательные статистики.
В наборе данных для каждой страны указано, сколько белка получает ежедневно житель из различных продуктов.

```{r}
protein <- import('Europenaprotein.csv')
skim(protein)
```

Отмасштабируем все числовые переменные с помощью функции `scale()`.
Затем спрячем текстовую переменную `Country` в названия строк:

```{r}
protein_no_country <- protein %>%
  mutate_if(is.numeric, ~ as.vector(scale(.))) %>%
  column_to_rownames(var = 'Country')
```

Дополнение в виде функции `as.vector` нужно потому, что функция `scale` возвращает матрицу,
а каждый столбец должен быть вектором :)


Выполним кластеризацию методом k-средних с помощью функции `kmeans`.

В качестве аргументов укажем отмасштабированные данные `protein_no_country` и количество кластеров `centers`.
Берём три кластера!
Сохраним результат кластеризации в список `k_means_protein`.

```{r}
k_means_protein <- kmeans(protein_no_country, centers = 3)
k_means_protein
```


TODO: Подробнее про межгрупповые дисперсии :)
Сюда добавить пару формул!!!



Как понять, сколько кластеров брать оптимально?
Один из способов сделать это — воспользоваться командой `fviz_nbclust` из пакета `factoextra`.


```{r}
g1 <- fviz_nbclust(protein_no_country, kmeans, method = 'wss') +
  labs(subtitle = 'Elbow method')
g1
```

TODO: подробнее про оси! Дадим русские подписи осям!




```{r}
g2 <- fviz_nbclust(protein_no_country, kmeans, method = 'silhouette') +
  labs(subtitle = 'Silhouette method')
g2
```




```{r}
g3 <- fviz_nbclust(protein_no_country, kmeans, method = 'gap_stat') +
  labs(subtitle = 'Gap statistic method')
g3
```




# Иерархическая кластеризация

Другой способ разбить данные на группы — иерархическая кластеризация.
Но, в отличие от метода k-средних, она работает с матрицей расстояний,
поэтому первым делом посчитаем её!
Для этого будем использовать функцию `dist()`.
Передадим ей стандартизированные данные и укажем явно, как считать расстояния с помощью аргумента `method`.
О всех остальных опциях можно узнать в справке.

```{r}
protein_dist <- dist(protein_no_country, method = 'euclidian')
```

Расстояния тоже можно визуализировать!
Сделаем это командой `fviz_dist` из пакета `factoextra`.

```{r}
fviz_dist(protein_dist)
```




* Упражнение 1.


Посчитайте матрицу расстояний для таблицы `usa_stand` и визуализируйте её.

```{r}
# usa <- USArrests
# usa_dist <- dist(___, method = 'euclidian')
# fviz_dist(___)
```

Полученную матрицу расстояний можно передадать функции `hclust()`, которая кластеризует данные.
Однако в пакете `factoextra` есть функция `hcut()`, которая работает с исходными данными.
Будем использовать её и попросим выделить четыре кластера в аргументе `k`.


```{r}
protein_hcl <- hcut(protein_no_country, k = 4)
```

С помощью функции `fviz_dend` визуализируем результат кластеризации.
Укажем несколько аргументов, чтобы сделать дендрограмму красивее,
а полный перечень найдётся в справке.

```{r}
fviz_dend(protein_hcl,
          cex = 0.5, # размер подписи
          color_labels_by_k = TRUE) # цвет подписей по группам
```

Выявленные кластеры можно добавить к исходным данным!
```{r}
protein_plus2 <- mutate(protein, cluster = protein_hcl$cluster)
glimpse(protein_plus2)
```


* Упражнение 2.

- Сделайте иерархическую кластеризацию с четыремя группами на данных об арестах.

- Визуализируйте результат кластеризации и сделайте подписи цветными.

```{r}
# usa_hcl <- hcut(___, k = ___)
# fviz_dend(___,
#          cex = 0.5, # размер подписи
#          color_labels_by_k = ___) # цвет подписей по группам
```

Иерархичская кластеризация полезна и для визуализаций корреляций.
Если в функции `corrplot()` из одноимённого пакета указать аргумента `order = hclust`,
то мы получим сгруппированные по кластерам переменные.
Для красоты добавим ещё один аргумент — `addrect = 3`.
Он обведёт прямоугольниками указанное число кластеров.

```{r}
protein_cor <- cor(protein_no_country)
corrplot(protein_cor, order = 'hclust', addrect = 3)
```

* Упражнение 3.

Визуализируйте корреляции в данных об арестах `usa` и сгруппируйте их по двум кластерам.
Замените кружочки на квадраты, передав аргументу `method` значение `shade`.

```{r}
# usa_cor <- cor(___)
# corrplot(___, order = ___, addrect = ___, ___ = ___)
```

* Упражнение 4.

Добавьте к исходным данным `usa` кластеры, полученные с помощью иерархической кластеризации:
```{r}
# usa_plus2 <- mutate(___, cluster = ___)
# glimpse(___)
```

Визуализации [кластеров в известных наборах данных] (https://cran.r-project.org/web/packages/dendextend/vignettes/Cluster_Analysis.html)


# Метод главных компонент

Метод главных компонент: заменяем большое количество исходных переменных на меньшее количество
новых искусственных переменных, главных компонент.

Например, можно заменить 20 исходных переменных на две искусственные главные компоненты,
чтобы изобразить многомерный набор данных на двумерном графике.

Как переменные превращают в главные компоненты?

Для удобства представим, что у нас есть три исходные переменные, они центрированы и приведены к общему масштабу.

Подход А. Максимизация разброса.

В первую компоненту берём исходные три переменные с такими весами, чтобы:

- максимизировать разброс первой главной компоненты;
- сумма квадратов весов равнялась бы единице.

Подход Б. Минимизация расстояний от точек до новой системы координат.

Мы хотим ввести новую прямую координат так,
чтобы прямая находилась на минимальном расстоянии от имеющихся точек.

Эти подходы эквивалентны.


Реализуем метод главных компонент на данных о потреблении белка функцией `prcomp()`.
Передадим ей отмасштабированные данные `protein_no_country`, хотя так поступать и необязательно.
Другой путь — передать исходный набора данных и попросить функцию `procmp()` стандартизировать их
аргументом  `scale = TRUE`.

```{r}
protein_pca <- procmp(protein_no_country)
protein_pca
```

TODO: что есть что в этом списке

Визуализируем данные в осях первых двух главных компонент.
Для этого воспользуемся функцией `fviz_pca_ind()` из пакета `factoextra`.
Рисовать будем `protein_pca`, а аргумент `repel = TRUE` укажем для того,
чтобы подписи на графике не перекрывали друг друга.

```{r}
fviz_pca_ind(protein_pca, repel = TRUE)
```

* Упражнение 5.

- Выделите главные компоненты на данных об арестах в Америке.
Будьте внимательны: эти данные мы не масштабировали!

- Визуализируйте данные в осях первых двух главных компонент.
Проследите, чтобы подписи точек на графике были аккуратными :)

```{r}
# usa_pca <- prcomp(___, scale. = ___)
# usa_pca
# fviz_pca_ind(___, repel = ___)
```

- Какой процент дисперсии объясняют в сумме первые две главные компоненты?
- Какой из штатов скорее можно назвать нетипичным, Калифорнию или Вирджинию?
- Какой из штатов наиболее похож на Техас?

Помимо самих данных, в осях главных компонент можно нарисовать проекции исходных переменных.
Сделаем это командой `fviz_pca_biplot()`.
Как и прежде, укажем, что мы хотим изобразить, и попросим сделать подписи аккуратными
аргументом `repel = TRUE`.

```{r}
fviz_pca_biplot(protein_pca, repel = TRUE)
```

- Какая исходная переменная входит в первую главную компоненту с большим положительным весом?
- Какая исходная переменная входит в первую главную компоненту с большим отрицательным весом?
- Как можно хотя бы примерно проинтепретировать первую главную компоненту?


* Упражнение 6.

Визуализируйте в осях первых двух главных компонент американские штаты и проекции
исходных переменных.

```{r}
# fviz_pca_biplot(___, ___ = TRUE)
```

- Какая исходная переменная входит в первую главную компоненту с большим отрицательным весом?
- Как можно хотя бы примерно проинтепретировать первую главную компоненту?
- Какие штаты можно считать самыми безопасными?


Теперь изобразим, какой процент разброса данных объясняет каждая главная компонента.
Будем использовать команду `fviz_eig()` из пакета `factoextra`.

```{r}
fviz_eig(protein_pca)
```

- Сколько нужно взять главных компонент, чтобы объяснить более 70% разброса исходных наблюдений?

* Упражнение 7.

Визиулизируйте процент разброса, который объясняет каждая главная компонента.
Обратите внимание, что у функции появился новый аргумент :)

```{r}
# fviz_eig(___, addlabels = TRUE)
```

- Какой процент разброса в данных объясняют в сумме третья и четвёртая глаыне компоненты?
- Что меняет аргумент `addlabels = TRUE`?


Выясним, какой влкад вносит каждая переменная в конкретную главную компоненту.
Для этого будем использовать команду `fviz_contrib()`.
Передадим ей объект `protein_pca` и в качестве аргументов укажем `choice = 'var'`,
так как нам нужны именно переменные, а не наблюдения, и `axes = 1`,
чтобы посмотреть на первую главную компоненту.
Для визуализации вклада наблюдения значение аргумента `choice` поменяем на `ind`
и для разнообразия посмотрим на третью главную компоненту :)

```{r}
fviz_contrib(protein_pca, choice = 'var', axes = 1)
fviz_contrib(protein_pca, choice = 'ind', axes = 3)
```

- Какие переменные имеют наибольший вес в первой главной компоненте?
- Какая страна вносит наибольший вклад в сумму квадратов расстояний до центра для третьей главной компоненты?

* Упражнение 8.

Для данных по арестам визуализируйте вклад переменных во вторую главную компоненту
и вклад наблюдений в первую.

```{r}
# fviz_contrib(___, choice = '___', axes = ___)
# fviz_contrib(___, choice = ___, ___ = ___)
```


В осях первых двух главных компонент исходные данные можно раскрасить согласно кластерам:

```{r}
fviz_cluster(object = k_means_protein,
             data = protein_no_country,
             ellipse.type = 'convex')
```

Теперь мы понимаем, что на этом графике!

Ура! :)
