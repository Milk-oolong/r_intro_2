---
title: 'Семинар 5. Множественная регрессия'
date: 'Июнь, 14, 2018'
output:
  html_document:
    keep_md: no
    number_sections: yes
    toc: yes
lang: ru-RU
editor_options:
  chunk_output_type: console
---



Шаманское заклинание для настройки глобальных опций отчёта:
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```
# Регрессия при гомоскедастичных ошибках

```{r}
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(broom) # метла превращает результаты оценивания моделей в таблички
library(GGally) # больше готовых графиков
library(sjPlot) # ещё больше графиков
library(lmtest) # диагностика линейных моделей
library(Ecdat) # много-много разных наборов данных
library(sjstats) # удобные мелкие функции для работы с моделями
```

Возьмём набор данных об изменении пульса студентов до и после упражнений.
Его описание доступно по [ссылке](http://www.statsci.org/data/oz/ms212.html).

Загрузим данные и посмотрим на описательные статистики.

Установите в качестве текущей папки ту папку, где лежит данный `.Rmd`-файл:
`Session` — `Set working directory` — `To source file location`.

Правильно укажите путь к данным относительно `.Rmd`-файла:

```{r}
pulse <- import('___/pulse.txt')
skim(pulse)
```

- Сколько в данных наблюдений? Сколько переменных?
- Какие переменные на самом деле являются факторными?

Вернём факторным переменным положенный статус!

```{r}
pulse_fct <- pulse %>%
  mutate_at(vars(-Weight, -Height, -Age, -Pulse1, -Pulse2), factor)
```

И теперь можно приступать к регрессиям.
Начнём с парной и построим регрессию пульса после упражнений `Pulse2` на константу и пульс до упражнений `Pulse1`.
Для этого воспользуемся командой `lm()` и передадим ей данные и формулу.

```{r}
model_r <- lm(data = pulse_fct, Pulse2 ~ Pulse1)
```

С помощью команды `summary()` посмотрим на описание модели.

```{r}
summary(model_r)
```

- На сколько в среднем отличается пульс после упражнений у двух студентов, если
пульс до упражнений у них отличается на единицу?
- Какие коэффициенты значимы?
- Какая доля разброса пульса после упражнений объясняется пульсом до упражнений?

* Упражнение 1.

Упражнения будем выполнять на встроенном наборе данных `Housing`.
Посмотрите описание переменных в справке :)
Затем «бросьте взгляд» на данные, есть ли в них факторные переменные, которые объявлены иначе?

```{r}
house <- Housing
# ___
```

Постройте парную регрессию цены дома `price` на константу и площадь дома `lotsize`.

```{r}
# house_r <- lm(data = ___, ___ ~ ___)
# summary(___)
```
TODO: вопросы


Другой способ посмотреть на описание модели — воспользоваться функциями пакета `broom`.
Оценки коэффциентов, стандартные ошибки, p-значения выводит команда `tidy()`:
```{r}
tidy(model_r)
```


А функция `glance()` покажет общие характеристики модели, для которых достаточно одной строчки, — коэффциент детерминации, значение лог-функции правдоподобия, AIC, BIC...

```{r}
glance(model_r)
```

Если из общей таблицы описания модели нужна только информация о коэффициентах, то поможет команда `coeftest()` из пакета `lmtest()`.

```{r}
coeftest(model_r)
```

Нарисуем линию регрессии для модели, в которой зависимая переменная — это пульс после упражнений, а объясняющая — пульс до упражнений.
Для этого к диаграмме рассеяния добавим дополнительный слой `geom_smooth()`.
Внутри него за линейную регрессию отвечает `method = 'lm'`.

```{r}
ggplot(data = pulse_fct, aes(x = Pulse1, y = Pulse2)) +
  geom_point() +
  geom_smooth(method = 'lm')
```

* Упражнение 2.

Визуализируйте линию регрессии для модели `house_r`.
В ней зависимой переменной была цена дома `price`, а объясняющей — площадь `lotsize`.

```{r}
# ggplot(data = ___, aes(x = ___, y = ___)) +
#   ___() +
#   geom_smooth(method = ___)
```

Теперь оценим более сложную модель.
К объясняющим переменным добавим вес студента `Weight` и бинарные переменные `Ran`, где 2 соответствует студенту, который выполнял упражнения , и `Smokes`, где значение 2 — это студент-курильщик.

```{r}
model_ur <- lm(data = pulse_fct, Pulse2 ~ Weight + Pulse1 + Ran + Smokes)
summary(model_ur)
```

* Упражнение 3.

Оцените более сложную модель для набора данных о домах.
Среди объясняющих переменных укажите площадь дома `lotsize`, количсевто спален `bedrooms`
и бинарную переменную `prefarea`, которая равна 1 для домов, расположенных в хороших районах.

```{r}
# house_ur <- lm(data = ___, ___ ~ ___)
# summary(___)
```

Есть ли проблемы у модели?
Диагностический график в студию!

```{r}
ggnostic(model = model_ur)
```

На этом графике четыре линии!
* Первая: зависимость величины остатка $\hat u_i = y_i - \hat y_i$ от каждого регрессора.
* Вторая: зависимость величины $\hat \sigma_i$ от каждого регрессора.

Величина $\hat \sigma_i$ показывает, какой была бы оценка стандартного отклонения случайной составляющей,
если бы $i$-ое наблюдение выкинули из модели.

Слишком маленькие значения $\hat \sigma_i$ говорят о том, что
при выкидывании наблюдения резко падает оценка стандартного отклонения. Значит, наблюдение могло быть выбросом.

* Третья: зависимость величины $h_{ii}$ от каждого регрессора.

Величина $h_{ii}$ имеет две интерпретации. Во-первых, она показывает, насколько изменится прогноз $\hat y_i$ при увеличении фактического наблюдения $y_i$ на единицу.
Во-вторых, эта величина показывает отношение дисперсии прогноза $\hat y_i$ к дисперсии случайной составляющей:
\[
h_{ii} = \frac{Var(\hat y_i)}{Var(u_i)}
\]

* Четвертая: зависимость расстояния Кука от каждого из регрессоров.

Подробнее про расстояние Кука можно прочитать TODO


TODO: вопросы к ggnostic (?)

Построим 5\%-ые доверительные интервалы для всех коэффициентов модели `model_ur`.
Для этого будем использовать команду `confint()`.
Поменять уровень значимости можно аргументом `level`.
Затем визуилизируем получившиеся доверительные интервалы командой `sjp.lm()` из пакета `sjPlot`.

```{r}
confint(model_ur)
sjp.lm(model_ur)
plot_model(model, ci.lvl = .9)
```

* Упражнение 4.

Постройте 5\%-ные доверительные интервалы для всех коэффициентов модели `house_ur`
и визуализируйте их.

```{r}
# confint(___)
# sjp.lm(___)
```


Если есть две вложенных модели, то есть одна является частным случаем другой,
то можно провести тест Вальда, чтобы выбрать одну из них.

$H_0$: верна ограниченная (короткая) модель;

$H_a$: верная неограниченная (длинная) модель;

```{r}
waldtest(model_r, model_ur)
```

Сравниваем p-значение с уровнем значимости.

* Упражнение 5.

Проведите тест Вальда для  моделей `house_r` и `huose_ur`.

```{r}
# waldtest(___, ___)
```

- Какую модель следует выбрать по результатам теста на 5\%-ом уровне значимости?


# О бедном t-тесте замолвите слово!

Иногда душа хочет проверки самых простых гипотез!

Если хочется построить доверительный интервал для математического ожидания пульса до упражнений,
то достаточно построить регрессию на константу:

```{r}
model_mu <- lm(data = pulse_fct, Pulse1 ~ 1)
confint(model_mu)
```

Если хочется построить доверительный интервал для разности математического ожидания пульса у курящих и некурящих,
то можно построить регрессию на константу и дамми-переменную.

```{r}
model_diff <- lm(data = pulse_fct, Pulse1 ~ Smokes)
confint(model_diff)
```

* Упражнение 6.

Постройте доверительный интервал для математического ожидания цены и
доверительный интервал для разности математических ожиданий цены дома в хорошем и обычном районе.

```{r}
# house_mu <- lm(data = ___, ___ ~ ___)
# summary(___)

# house_diff <- lm(data = ___, ___ ~ ___)
# summary(___)
```

Дисперсионный анализ легким движением руки также заменяется на построение единственной регрессии.

Проверим, что две качественные переменные, `Smokes` и  `Gender`, не оказывают влияния на частоту пульса.


```{r}
model_2anova <- lm(data = pulse_fct, Pulse1 ~ Smokes * Gender)
summary(model_2anova)
anova_stats(model_2anova)
```

* Упражнение 7.

Проверьте, что наличие подъезда к дому `driveway` и расположение в хорошем районе `prefarea`,
не влияют на цену дома.

```{r}
# house_2anova <- lm(data = ___, ___ ~ ___ * ___)
# summary(___)
```


# Регрессия при гетероскадистичных ошибках

Если не предполагать, что дисперсии ошибок $Var(u_i)$ одинаковы для всех наблюдений,
то построенные нами доверительные интервалы и выполненная проверка гипотез — полный отстой :)

Повторяем табличку с тестами на значимость отдельных коэффициентов с учётом поправки на гетероскедастичность.

```{r}
robust(model_ur)
```

Также легко получить доверительные интервалы:

```{r}
robust(model_ur, conf.int = TRUE)
```

Результаты в R чуть отличаются от результатов в stata.
По-умолчанию, R использует корректировку HC3 для подсчёта стандартных ошибок коэффициентов, а stata — менее удачную, устаревшую HC1.
Сравнение есть у [Achim Zeileis](https://cran.r-project.org/web/packages/sandwich/vignettes/sandwich.pdf).
Если хочется воспроизвести именно корректировку HC1, то запросто :)

```{r}
robust(model_ur, vcov = 'HC1')
```

Сравним две вложенных модели с учётом поправки на гетероскедастичность:
```{r}
waldtest(model_r, model_ur, vcov = vcovHC)
```

* Упражнение 8.

Получите таблицу с тестами на значимость коэффициентов в модели `house_ur`,
используя корректировку `HC3`.
А затем сравните две модели `house_r` и `house_ur` с учётом поправки на гетероскедастичность.

```{r}
# robust(___, vcov = '___')
# waldtest(___, ___, vcov =  vcovHC)
```


# Инструментальные переменные


теория [Б]
