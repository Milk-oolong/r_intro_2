---
title: 'Семинар 5. Множественная регрессия'
date: 'Июнь, 14, 2018'
output:
  html_document:
    keep_md: no
    number_sections: yes
    toc: yes
lang: ru-RU
editor_options:
  chunk_output_type: console
---



Шаманское заклинание для настройки глобальных опций отчёта:
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```
# Регрессия при гомоскедастичных ошибках

```{r}
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(broom) # метла превращает результаты оценивания моделей в таблички
library(GGally) # больше готовых графиков
library(sjPlot) # ещё больше графиков
library(lmtest) # диагностика линейных моделей
```

Возьмём набор данных об изменении пульса студентов до и после упражнений.
Его описание доступно по [ссылке](http://www.statsci.org/data/oz/ms212.html).

Загрузим данные и посмотрим на описательные статистики.

```{r}
pulse <- import('data/pulse.txt')
skim(pulse)
```

- Сколько в данных наблюдений? Сколько переменных?
- Какие переменные на самом деле являются факторными?

Вернём факторным переменным положенный статус!

```{r}
pulse_fct <- pulse %>%
  mutate_at(vars(-Weight, -Height, -Age, -Pulse1, -Pulse2), factor)
```

И теперь можно приступать к регрессиям.
Начнём с парной и построим регрессию пульса после упражнений `Pulse2` на константу и пульс до упражнений `Pulse1`.
Для этого воспользуемся командой `lm()` и передадим ей данные и формулу.

```{r}
model_r <- lm(data = pulse_fct, Pulse2 ~ Pulse1)
```

С помощью команды `summary()` посмотрим на описание модели.

```{r}
summary(model_r)
```

- На сколько в среднем отличается пульс после упражнений у двух студентов, если
пульс до упражнений у них отличается на единицу?
- Какие коэффициенты значимы?
- Какая доля разброса пульса после упражнений объясняется пульсом до упражнений?


Другой способ посмотреть на описание модели — воспользоваться функциями пакета `broom`.
Оценки коэффциентов, стандартные ошибки, p-значения выводит команда `tidy()`:
```{r}
tidy(model_r)
```


А функция `glance()` покажет общие характеристики модели, для которых достаточно одной строчки, — коэффциент детерминации, значение лог-функции правдоподобия, AIC, BIC...

```{r}
glance(model_r)
```

Если из общей таблицы описания модели нужна только информация о коэффициентах, то поможет команда `coeftest()` из пакета `lmtest()`.

```{r}
coeftest(model_r)
```

Нарисуем линию регрессии для модели, в которой зависимая переменная — это пульс после упражнений, а объясняющая — пульс до упражнений.
Для этого к диаграмме рассеяния добавим дополнительный слой `geom_smooth()`.
Внутри него за линейную регрессию отвечает `method = 'lm'`.

```{r}
ggplot(data = pulse_fct, aes(x = Pulse1, y = Pulse2)) +
  geom_point() +
  geom_smooth(method = 'lm')
```

Теперь оценим более сложную модель.
К объясняющим переменным добавим вес студента `Weight` и бинарные переменные `Ran`, где 2 соответствует студенту, который выполнял упражнения , и `Smokes`, где значение 2 — это студент-курильщик.

```{r}
model_ur <- lm(data = pulse_fct, Pulse2 ~ Weight + Pulse1 + Ran + Smokes)
summary(model_ur)
```



```{r}
ggnostic(model = model_ur)
```

Построим 5%-ые доверительные интервалы для всех коэффициентов модели `model_ur`.
Для этого будем использовать команду `confint()`.
Поменять уровень значимости можно аргументом `level`.
Затем визуилизируем получившиеся доверительные интервалы командой `sjp.lm()` из пакета `sjPlot`.

```{r}
confint(model_ur)
sjp.lm(model_ur)
```

Если есть две вложенных модели, то есть одна является частным случаем другой,
то можно провести тест Вальда, чтобы выбрать одну из них.

$H_0$: верна ограниченная (короткая) модель;

$H_a$: верная неограниченная (длинная) модель;

```{r}
waldtest(model_r, model_ur)
```

Сравниваем p-значение с уровнем значимости.


# О бедном t-тесте замолвите слово!

Иногда душа хочет проверки самых простых гипотез!

Если хочется построить доверительный интервал для математического ожидания,
то достаточно построить регрессию на константу:

```{r}
model_mu <- lm(data = , ~ 1)
confint(model_mu)
```

Если хочется построить доверительный интервал для разности средних в двух группах,
то можно построить регрессию на константу и дамми-переменную

```{r}
model_diff <- lm(data = , ~ )
confint(model_diff)
```

Дисперсионный анализ легким движением руки также заменяется на построение единственной регрессии.



# Регрессия при гетероскадистичных ошибках

Если не предполагать, что дисперсии ошибок $Var(u_i)$ одинаковы для всех наблюдений,
то построенные нами доверительные интервалы и выполненная проверка гипотез — полный отстой :)

Повторяем табличку с тестами на значимость отдельных коэффициентов с учётом поправки на гетероскедастичность
```{r}
robust(model_ur)
```

Также легко получить доверительные интервалы:
```{r}
robust(model_ur, conf.int = TRUE)
```

Результаты в R чуть отличаются от результатов в stata.
По-умолчанию, R использует корректировку HC3 для подсчёта стандартных ошибок коэффициентов, а stata — менее удачную, устаревшую HC1.
Сравнение есть у [Achim Zeileis](https://cran.r-project.org/web/packages/sandwich/vignettes/sandwich.pdf).
Если хочется воспроизвести именно корректировку HC1, то запросто :)

```{r}
robust(model_ur, type = 'HC1')
```

Сравним две вложенных модели с учётом поправки на гетероскедастичность:
```{r}
waldtest(model_r, model_ur, .vcov = vcovHC)
```




# Инструментальные переменные
